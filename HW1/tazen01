import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.tree import DecisionTreeClassifier
import matplotlib.pyplot as plt
from sklearn import tree
import os
from sklearn.metrics import ConfusionMatrixDisplay
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.neural_network import MLPClassifier
from sklearn.inspection import permutation_importance

train_file = "HW1/credit_train(in).csv"
test_file = "HW1/credit_test(in).csv"

# Ensure reports directory exists
if not os.path.exists('reports'):
    os.makedirs('reports')

# Decision Tree Explanation
def DT_Explain(train_file, test_file):
    # Load the dataset
    train_data = pd.read_csv(train_file)
    test_data = pd.read_csv(test_file)

    # Preprocess the data
    X_train_full = train_data.drop(columns=['approved'])
    y_train_full = train_data['approved']
    X_test = test_data.drop(columns=['approved'])
    y_test = test_data['approved']

    # Split the data
    X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.2, random_state=42)

    # Build the decision tree model
    dt_model = DecisionTreeClassifier(max_depth=10, random_state=42)

    # Train the model
    dt_model.fit(X_train, y_train)

    # Make predictions
    y_train_predictions = dt_model.predict(X_train)
    y_test_predictions = dt_model.predict(X_test)

    # Evaluate the model
    train_accuracy = accuracy_score(y_train, y_train_predictions)
    test_accuracy = accuracy_score(y_test, y_test_predictions)

    # Print train and test accuracy
    print(f"DT Train Accuracy: {train_accuracy:.2f}")
    print(f"DT Test Accuracy: {test_accuracy:.2f}")

    # Visualize the decision tree
    plt.figure(figsize=(20, 10))
    class_names = [str(cls) for cls in sorted(y_train.unique())]
    tree.plot_tree(dt_model, filled=True, feature_names=X_train.columns, class_names=class_names)
    plt.savefig("reports/decision_tree_plot.png")

    # Visualize the feature importance
    importances = dt_model.feature_importances_
    feature_importance = list(zip(X_train.columns, importances))

    for feature, importance in feature_importance:
        print(f"{feature}: {importance:.4f}")
    
    features = [f[0] for f in feature_importance]
    scores = [f[1] for f in feature_importance]

    plt.figure(figsize=(10, 6))
    plt.barh(features, scores, color="skyblue")
    plt.xlabel("Feature Importance Score")
    plt.ylabel("Feature")
    plt.title("Feature Importance in Decision Tree")
    plt.gca().invert_yaxis()
    plt.savefig("reports/Feature_Importance_Decision_Tree.png")

    # Generate report
    train_report = classification_report(y_train, y_train_predictions)
    test_report = classification_report(y_test, y_test_predictions)
    train_conf_matrix = confusion_matrix(y_train, y_train_predictions)
    test_conf_matrix = confusion_matrix(y_test, y_test_predictions)
    with open("reports/decision_tree_report.txt", 'w') as f:
        f.write(f"DT Train Accuracy: {train_accuracy:.2f}\n\n")
        f.write(f"DT Test Accuracy: {test_accuracy:.2f}\n\n")
        f.write("DT Train Classification Report:\n\n")
        f.write(train_report)
        f.write("\nDT Test Classification Report:\n\n")
        f.write(test_report)
        f.write("\nDT Train Confusion Matrix: \n")
        f.write(str(train_conf_matrix))
        f.write("\n\nDT Test Confusion Matrix: \n")
        f.write(str(test_conf_matrix))

# Logistic Regression Explanation
def LR_Explain(train_file, test_file):
    # Load the dataset
    train_data = pd.read_csv(train_file)
    test_data = pd.read_csv(test_file)

    # Preprocess the data
    X = train_data.drop(columns='approved')
    y = train_data['approved']

    # Normalize the data
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    X_test_scaled = scaler.transform(test_data.drop(columns='approved'))

    # Split the data
    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

    # Initialize the logistic regression model
    lr_model = LogisticRegression(random_state=42, max_iter=100)

    # Model training
    lr_model.fit(X_train, y_train)

    # Make predictions
    X_train_predictions = lr_model.predict(X_train)
    X_test_predictions = lr_model.predict(X_test)

    # Evaluate the model
    train_accuracy = accuracy_score(y_train, X_train_predictions)
    test_accuracy = accuracy_score(y_test, X_test_predictions)

    # Print train and test accuracy
    print(f"LR Train Accuracy: {train_accuracy:.2f}")
    print(f"LR Test Accuracy: {test_accuracy:.2f}")

    # Visualize the feature importance (coefficients of logistic regression)
    coefficients = lr_model.coef_[0]
    feature_importance = pd.DataFrame({
        'Feature': train_data.drop(columns='approved').columns,
        'Coefficient': coefficients
    }).sort_values(by='Coefficient', ascending=False)

    # Plot feature importance
    plt.figure(figsize=(10, 6))
    plt.barh(feature_importance['Feature'], feature_importance['Coefficient'], color='skyblue')
    plt.xlabel("Coefficient Value")
    plt.ylabel("Feature")
    plt.title("Feature Importance (Logistic Regression Coefficients)")
    plt.gca().invert_yaxis()
    plt.savefig("reports/Feature_Importance_Logistic_Regression.png")
    plt.show()

    # Confusion Matrix Display
    ConfusionMatrixDisplay.from_predictions(y_test, X_test_predictions, display_labels=sorted(y_test.unique()), cmap='Blues')
    plt.title("LR Confusion Matrix")
    plt.savefig("reports/Logistic_Regression_Confusion_Matrix.png")

    # Generate report
    train_report = classification_report(y_train, X_train_predictions)
    test_report = classification_report(y_test, X_test_predictions)
    train_conf_matrix = confusion_matrix(y_train, X_train_predictions)
    test_conf_matrix = confusion_matrix(y_test, X_test_predictions)
    with open("reports/logistic_regression_report.txt", 'w') as f:
        f.write(f"LR Train Accuracy: {train_accuracy:.2f}\n\n")
        f.write(f"LR Test Accuracy: {test_accuracy:.2f}\n\n")
        f.write("LR Train Classification Report:\n\n")
        f.write(train_report)
        f.write("\nLR Test Classification Report:\n\n")
        f.write(test_report)
        f.write("\nLR Train Confusion Matrix: \n")
        f.write(str(train_conf_matrix))
        f.write("\n\nLR Test Confusion Matrix: \n")
        f.write(str(test_conf_matrix))

# MLP Explanation
def MLP_Explain(train_file, test_file):
    # Load the dataset
    train_data = pd.read_csv(train_file)
    test_data = pd.read_csv(test_file)

    # Preprocess the data
    X = train_data.drop(columns='approved')
    y = train_data['approved']

    # StandardScaler
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    X_test_scaled = scaler.transform(test_data.drop(columns='approved'))

    # Split the data
    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

    # Initialize the model
    mlp_model = MLPClassifier(hidden_layer_sizes=(10,), random_state=42, max_iter=1100)

    # Model train
    mlp_model.fit(X_train, y_train)

    # Make predictions
    X_train_predictions = mlp_model.predict(X_train)
    X_test_predictions = mlp_model.predict(X_test)

    # Evaluate the model
    train_accuracy = accuracy_score(y_train, X_train_predictions)
    test_accuracy = accuracy_score(y_test, X_test_predictions)

    # Print train and test accuracy
    print(f"MLP Train Accuracy: {train_accuracy:.2f}")
    print(f"MLP Test Accuracy: {test_accuracy:.2f}")

    # Permutation Feature Importance
    perm_importance = permutation_importance(mlp_model, X_test, y_test, n_repeats=10, random_state=42)

    # Extract feature names and importance scores
    feature_names = train_data.columns[:-1]
    importance_values = perm_importance.importances_mean

    print("\nMLP Permutation Feature Importance:")
    for feature, importance in zip(feature_names, importance_values):
        print(f"{feature}: {importance:.4f}")

    # Create DataFrame for sorting and visualization
    importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importance_values})
    importance_df = importance_df.sort_values(by='Importance', ascending=False)

    # Visualize feature importance
    plt.figure(figsize=(10, 6))
    plt.barh(importance_df['Feature'], importance_df['Importance'], color='skyblue')
    plt.xlabel("Importance Score")
    plt.ylabel("Feature")
    plt.title("MLP Feature Importance (Permutation)")
    plt.gca().invert_yaxis()

    # Save the plot
    plt.savefig("reports/MLP_Feature_Importance.png")
    plt.show()

    # Generate report
    train_report = classification_report(y_train, X_train_predictions)
    test_report = classification_report(y_test, X_test_predictions)
    train_conf_matrix = confusion_matrix(y_train, X_train_predictions)
    test_conf_matrix = confusion_matrix(y_test, X_test_predictions)
    with open("reports/MLP_report.txt", 'w') as f:
        f.write(f"MLP Train Accuracy: {train_accuracy:.2f}\n\n")
        f.write(f"MLP Test Accuracy: {test_accuracy:.2f}\n\n")
        f.write("MLP Train Classification Report:\n\n")
        f.write(train_report)
        f.write("\nMLP Test Classification Report:\n\n")
        f.write(test_report)
        f.write("\nMLP Train Confusion Matrix: \n")
        f.write(str(train_conf_matrix))
        f.write("\n\nMLP Test Confusion Matrix: \n")
        f.write(str(test_conf_matrix))

# Run the functions
DT_Explain(train_file, test_file)
LR_Explain(train_file, test_file)
MLP_Explain(train_file, test_file)
